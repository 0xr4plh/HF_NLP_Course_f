<FrameworkSwitchCourse {fw} />

<div dir="rtl">

# کوک کردن مدل‌ها با استفاده از کِراس

# Fine-tuning a model with Keras

<DocNotebookDropdown
  classNames="absolute z-10 right-0 top-0"
  options={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},
]} />

وقتی که شما همه کارهای پیش‌پردازش در بخش قبل را انجام دادید، فقط چند مرحله با‌قیمانده تا تعلیم مدل دارید. با این حال، توجه داشته باشید که دستور <span dir="ltr">`model.fit()`</span> روی CPU بسیار آهسته اجرا خواهد شد. اگر GPU ندارید، می‌توانید از GPUها یا TPUهای مجانی روی [گوگل کولَب](https://colab.research.google.com/) استفاده کنید.

Once you've done all the data preprocessing work in the last section, you have just a few steps left to train the model. Note, however, that the `model.fit()` command will run very slowly on a CPU. If you don't have a GPU set up, you can get access to free GPUs or TPUs on [Google Colab](https://colab.research.google.com/).

نمونه کدهای زیر فرض می‌کنند شما مثال‌های بخش قبل را از پیش اجرا کرده‌اید. این یک خلاصه کوتاه است جهت یادآوری آنچه نیاز دارید:

The code examples below assume you have already executed the examples in the previous section. Here is a short summary recapping what you need:

<div dir="ltr">

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding
import numpy as np

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)

tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")

tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)
```

</div>

### تعلیم

مدل‌های تِنسورفِلو که از ترَنسفورمِرهای هاگینگ‌فِیس وارد شده‌اند از پیش مدل‌های کِراس هستند. این هم مقدمه‌ای کوتاه به کِراس.

TensorFlow models imported from 🤗 Transformers are already Keras models. Here is a short introduction to Keras.

<Youtube id="rnTGBy2ax1c"/>

جمله بالا به این معنی است که به محض اینکه داده‌مان را در اختیار بگیریم، کار بسیار کمی لازم است تا تعلیم را روی آن شروع کنیم.

That means that once we have our data, very little work is required to begin training on it.

<Youtube id="AUozVp78dhk"/>

مانند [فصل قبل](/course/chapter2)، ما از کلاس `TFAutoModelForSequenceClassification` با دو برچسب‌دسته استفاده خواهیم کرد:

As in the [previous chapter](/course/chapter2), we will use the `TFAutoModelForSequenceClassification` class, with two labels: 

<div dir="ltr">

```py
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

</div>

شما متوجه خواهید شد که برخلاف [فصل ۲](/course/chapter2)، بعد از ساختن این مدل از پیش‌ تعلیم دیده یک هشدار دریافت می‌کنید. این به این خاطر است که BERT برای دسته‌بندی دو جمله‌ها از پیش‌ تعلیم ندیده است، بنابراین لایه-سر مدل از پیش‌ تعلیم دیده حذف شده و یک لایه-سر مناسب جهت دسته بندی رشته‌‌‌ها به جای آن قرار گرفته است. هشدارها نشان می‌دهند که برخی از وزن‌های مدل استفاده نشده‌اند (آنهایی که مربوط به لایه-سر حذف شده مدل از پیش تعلیم دیده هستند) و برخی دیگر به صورت تصادفی مقدار‌ دهی شده‌‌اند (آنهایی که مربوط به لایه-سر جدید هستند). در نتیجه این امر شما را تشویق به تعلیم مدل می‌کند، که دقیقا همان چیزی است که می‌خواهیم اکنون انجام دهیم.

You will notice that unlike in [Chapter 2](/course/chapter2), you get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been inserted instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head). It concludes by encouraging you to train the model, which is exactly what we are going to do now.

برای کوک‌ کردن مدل روی دِیتاسِت‌مان، ما فقط باید مدل را <span dir="ltr">`compile()`</span> کنیم و سپس داده‌مان را به تابع <span dir="ltr">`fit()`</span> ارسال کنیم. این کار فرایند کوک‌ کردن را شروع می‌کند (که باید چند دقیقه روی GPU طول بکشد) و در همین حین هزینه تعلیم و هزینه تایید را در انتهای هر epoch گزارش می‌دهد.

To fine-tune the model on our dataset, we just have to `compile()` our model and then pass our data to the `fit()` method. This will start the fine-tuning process (which should take a couple of minutes on a GPU) and report training loss as it goes, plus the validation loss at the end of each epoch.

<Tip>

توجه داشته باشید که مدل‌های ترَنسفورمِر هاگینگ‌فِیس قابلیت ویژه‌ای دارند که بسیاری از مدل‌های کِراس ندارند - آنها می‌توانند به صورت خودکار از یک تابع هزینه مناسب که به صورت داخلی محاسبه می‌کنند استفاده کنند. در صورتی که شما آرگومانی برای تابع هزینه در زمان <span dir="ltr">`compile()`</span> تعیین نکنید آنها از این تابع هزینه به صورت پیش‌فرض استفاده خواهند کرد. توجه داشته باشید که جهت استفاده از تابع هزینه داخلی شما نیاز خواهید داشت برچسب‌دسته‌های خودتان را به عنوان بخشی از ورودی ارسال کنید، نه به صورت یک برچسب‌دسته مجزا، که روش معمول استفاده از برچسب‌دسته‌ها در مدل‌های کِراس می‌باشد. شما مثال‌هایی از این را در بخش ۲ این درس خواهید دید، جایی که تعیین تابع هزینه درست می‌تواند تا اندازه‌ای پیچیده باشد. به هر حال، برای دسته‌بندی رشته‌‌‌ها، یک تابع هزینه استانداد کِراس به خوبی کار می‌کند، چیزی که ما در اینجا استفاده خواهیم کرد.

Note that 🤗 Transformers models have a special ability that most Keras models don't - they can automatically use an appropriate loss which they compute internally. They will use this loss by default if you don't set a loss argument in `compile()`. Note that to use the internal loss you'll need to pass your labels as part of the input, not as a separate label, which is the normal way to use labels with Keras models. You'll see examples of this in Part 2 of the course, where defining the correct loss function can be tricky. For sequence classification, however, a standard Keras loss function works fine, so that's what we'll use here.

</Tip>

<div dir="ltr">

```py
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model.compile(
    optimizer="adam",
    loss=SparseCategoricalCrossentropy(from_logits=True),
    metrics=["accuracy"],
)
model.fit(
    tf_train_dataset,
    validation_data=tf_validation_dataset,
)
```

</div>

<Tip warning={true}>

در اینجا توجه شما را به یک مسئله عام جلب می‌کنیم - شما *می‌توانید* فقط نام تابع هزینه را به صورت یک متغیر متنی برای کِراس ارسال کنید، اما کِراس به صورت پیش‌فرض فکر می‌کند شما یک لایه softmax از پیش به خروجی‌تان اعمال کرده‌اید. با این حال، بسیاری از مدل‌ها مقادیر را درست قبل از اینکه softmax اعمال شود به خروجی می‌دهند، که به آنها *logits* نیز گفته می‌شوند. ما نیاز داریم که به تابع هزینه بگوییم، این کاری است که مدل‌مان انجام می‌دهد و تنها راه گفتن آن این است که به جای ارسال نام تابع هزینه به صورت متغیر متنی، آن را به صورت مستقیم صدا بزنیم.

Note a very common pitfall here — you *can* just pass the name of the loss as a string to Keras, but by default Keras will assume that you have already applied a softmax to your outputs. Many models, however, output the values right before the softmax is applied, which are also known as the *logits*. We need to tell the loss function that that's what our model does, and the only way to do that is to call it directly, rather than by name with a string.

</Tip>

### بهبود کارایی آموزش

### Improving training performance

<Youtube id="cpzq6ESSM5c"/>

اگر کد بالا را امتحان کنید، قطعا اجرا خواهد شد، اما متوجه خواهید شد که هزینه بسیار آهسته یا به صورت گاه و بیگاه کاهش می‌یابد. علت اصلی این امر *نرخ یادگیری* می‌باشد. مانند تابع هزینه، وقتی که ما نام بهینه‌ساز را به صورت یک متغیر متنی به کِراس ارسال می‌کنیم، کِراس همه پارامترهای آن، شامل نرخ یادگیری، را با مقادیر پیش‌فرض مقداردهی اولیه می‌کند. به تجربه طولانی، ما می‌دانیم که مدل‌های ترَنسفورمِر از نرخ‌های یادگیری بسیار کوچکتر بهره بیشتری می‌برند تا مقدار پیش‌فرض برای بهینه‌ساز Adam، که <span dir="ltr">1e-3</span> می‌باشد و همچنین به صورت 10 به توان <span dir="ltr">-3</span>، یا 0.001 نیز نوشته میشود.

If you try the above code, it certainly runs, but you'll find that the loss declines only slowly or sporadically. The primary cause
is the *learning rate*. As with the loss, when we pass Keras the name of an optimizer as a string, Keras initializes
that optimizer with default values for all parameters, including learning rate. From long experience, though, we know
that transformer models benefit from a much lower learning rate than the default for Adam, which is 1e-3, also written
as 10 to the power of -3, or 0.001. 5e-5 (0.00005), which is some twenty times lower, is a much better starting point.

علاوه بر کم کردن نرخ یادگیری، ما ترفند دیگری در آستین داریم: ما می‌توانیم نرخ یادگیری را به آهستگی در طول دوره تعلیم کاهش دهیم. در متون مشابه گاها خواهید دید که از این روش با عنوان نرخ یادگیری *محو شونده* یا *بازپختی نیز یاد می‌شود. بهترین روش برای انجام این کار در کِراس استفاده از *زمانبند نرخ یادگیری* است.* یک زمانبند خوب برای استفاده `PolynomialDecay` می‌باشد - این زمانبند برخلاف نامش نرخ یادگیری را در حالت پیش‌فرض به صورت خطی از مقدار اولیه تا مقدار نهایی  در طول دوره تعلیم کاهش می‌دهد که دقیقا همان چیزی است که ما می‌خواهیم. به منظور استفاده درست از زمانبند ما نیاز داریم که به آن بگوییم طول زمان تعلیم چقدر خواهد بود. در زیر ما آن را به عنوان `num_train_steps` محاسبه می‌کنیم.  

In addition to lowering the learning rate, we have a second trick up our sleeve: We can slowly reduce the learning rate
over the course of training. In the literature, you will sometimes see this referred to as *decaying* or *annealing*
the learning rate. In Keras, the best way to do this is to use a *learning rate scheduler*. A good one to use is
`PolynomialDecay` — despite the name, with default settings it simply linearly decays the learning rate from the initial
value to the final value over the course of training, which is exactly what we want. In order to use a scheduler correctly,
though, we need to tell it how long training is going to be. We compute that as `num_train_steps` below.

<div dir="ltr">

```py
from tensorflow.keras.optimizers.schedules import PolynomialDecay

batch_size = 8
num_epochs = 3
# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied
# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,
# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.
num_train_steps = len(tf_train_dataset) * num_epochs
lr_scheduler = PolynomialDecay(
    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps
)
from tensorflow.keras.optimizers import Adam

opt = Adam(learning_rate=lr_scheduler)
```

</div>

<Tip>

کتابخانه ترنسفورمرهای هاگینگ‌فِیس همچنین یک تابع `create_optimizer()` دارد که یک بهینه‌ساز `AdamW` دارای اندازه کاهش نرخ یادگیری می‌سازد. این یک میانبر مناسب است که آنرا با جزئیات در بخش‌های بعدی این آموزش خواهید دید.

The 🤗 Transformers library also has a `create_optimizer()` function that will create an `AdamW` optimizer with learning rate decay. This is a convenient shortcut that you'll see in detail in future sections of the course.

</Tip>

اکنون بهینه ساز کاملا جدیدمان را در اختار داریم و می‌توانیم آنرا تعلیم دهیم. ابتدا، اجازه دهید مدل را مجددا بارگذاری کنیم تا تغییرات ایجاد شده بر وزنها که در تعلیم قبلی اعمال شده‌اند را به حالت اولیه بازگردانیم، سپس می‌توانیم مدل را با بهینه ساز جدید تدوین کنیم: 

Now we have our all-new optimizer, and we can try training with it. First, let's reload the model, to reset the changes to the weights from the training run we just did, and then we can compile it with the new optimizer:

<div dir="ltr">

```py
import tensorflow as tf

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer=opt, loss=loss, metrics=["accuracy"])
```

</div>

Now, we fit again:

<div dir="ltr">

```py
model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)
```

</div>

<Tip>

اگر مایلید مدلتان را در حین تعلیم به صورت خودکار در هاب بارگذاری کنید، می‌توانید پارامتر `PushToHubCallback` را در تابع <span dir="ltr">`model.fit()`</span> ارسال کنید. در این‌باره در [Chapter 4](/course/chapter4/3) بیشتر خواهیم آموخت. 

💡 If you want to automatically upload your model to the Hub during training, you can pass along a `PushToHubCallback` in the `model.fit()` method. We will learn more about this in [Chapter 4](/course/chapter4/3)

</Tip>

# پیش‌بینی‌های مدل

### Model predictions

<Youtube id="nx10eh4CoOs"/>

تعلیم و تماشای پایین رفتن هزینه خیلی خوب است، اما چه کار کنیم اگر واقعا بخواهیم از مدل تعلیم دیده‌مان، چه برای محاسبه برخی معیار‌ها یا چه برای استفاده در خط تولید، خروجی دریافت کنیم؟ برای انجام این کار می‌توانیم از تابع <span dir="ltr">`predict()`</span> استفاده کنیم. این کار *logits* را از لایه سر خروجی مدل، یکی به ازای هر کلاس، باز می‌گرداند.


Training and watching the loss go down is all very nice, but what if we want to actually get outputs from the trained model, either to compute some metrics, or to use the model in production? To do that, we can just use the `predict()` method. This will return the *logits* from the output head of the model, one per class.

<div dir="ltr">

```py
preds = model.predict(tf_validation_dataset)["logits"]
```

</div>

ما می‌توانیم logitها را با استفاده از  `argmax` برای یافتن بزرگترین لاجیت، که نماینده محتمل ترین دسته می‌باشد به پیش‌بینی‌های دسته مدل تبدیل کنیم،

We can convert these logits into the model's class predictions by using `argmax` to find the highest logit, which corresponds to the most likely class:

<div dir="ltr">

```py
class_preds = np.argmax(preds, axis=1)
print(preds.shape, class_preds.shape)
```

</div>

<div dir="ltr">

```python out
(408, 2) (408,)
```

</div>

اکنون، اجازه دهید از `preds` برای محاسبه برخی معیارها استفاده کنیم! ما می‌توانیم معیارهای مرتبط با دیتاسِت MRPC را، به همان آسانی که دیتاسِت را بارگذاری کردیم، بارگذاری کنیم اما این بار با استفاده از تابع <span dir="ltr">`load_metric()`</span>. شیء باز گردانده شده تابعی به نام <span dir="ltr">`compute()`</span> دارد که می‌توانیم برای محاسبه معیارها از آن استفاده کنیم:

Now, let's use those `preds` to compute some metrics! We can load the metrics associated with the MRPC dataset as easily as we loaded the dataset, this time with the `load_metric()` function. The object returned has a `compute()` method we can use to do the metric calculation:

<div dir="ltr">

```py
from datasets import load_metric

metric = load_metric("glue", "mrpc")
metric.compute(predictions=class_preds, references=raw_datasets["validation"]["label"])
```

</div>

<div dir="ltr">

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

</div>

از آنجایی که مقداردهی اولیه تصادفی در لایه‌سر مدل ممکن است مقادیر معیارهای حاصل را تغییر دهد، نتایج دریافتی شما می‌توانند متفاوت باشند. در اینجا می‌بینیم که مدل ما دقتی معادل <span dir="ltr">85.78%</span> و <span dir="ltr">F1 score</span> معادل <span dir="ltr">89.97</span> روی مجموعه آزمون دارد. این‌‌ها دو معیاری هستند که جهت سنجش نتایج روی داده MRPC در محک GLUE به کار رفته‌اند. جدول نتایج در مقاله [BERT](https://arxiv.org/pdf/1810.04805.pdf)، <span dir="ltr">F1 score</span> برابر با <span dir="ltr">88.9</span> برای مدل پایه گزارش کرده است. آن مدل `uncased` بود در حالی که اکنون از مدل `cased` استفاده می‌کنیم، که نتایج بهتر را توجیح میکند.

The exact results you get may vary, as the random initialization of the model head might change the metrics it achieved. Here, we can see our model has an accuracy of 85.78% on the validation set and an F1 score of 89.97. Those are the two metrics used to evaluate results on the MRPC dataset for the GLUE benchmark. The table in the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf) reported an F1 score of 88.9 for the base model. That was the `uncased` model while we are currently using the `cased` model, which explains the better result.

به این ترتیب مقدمه کوک کردن با استفاده از `API` کِراس به پایان می‌رسد. یک مثال از انجام این کار برای معمول‌ترین مسئله‌های `NLP` در فصل ۷ ارائه خواهد شد. اگر مایلید خود را روی `API` کِراس کار آزموده کنید، سعی کنید مدلی را روی مسئله `GLUE SST-2`, با استفاده از روش پردازش داده‌ای که در بخش ۲ انجام دادید, کوک کنید.

This concludes the introduction to fine-tuning using the Keras API. An example of doing this for most common NLP tasks will be given in Chapter 7. If you would like to hone your skills on the Keras API, try to fine-tune a model on the GLUE SST-2 dataset, using the data processing you did in section 2.

</div>