### Load models from the Hugging Face Hub
Browse through the thousands of models Hugging Face has to offer [Chapter 4](/course/chapter4/section2).
It is especially easy to demo a `transformers` model from Hugging Face's Model Hub. Using the special `gr.Interface.load()` method, you pass `model/` or `huggingface/` followed by the model name. For example, here is the code to build a demo for [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6B), a large language model & add a couple of examples inputs:
    
    ```
    import gradio as gr
    
    examples = [["The Moon's orbit around Earth has"], ["There once was a pineapple"]]
    
    gr.Interface.load("huggingface/EleutherAI/gpt-j-6B", examples=examples).launch();
    ```
    
The code above will produce an interface like the one below:

<p align="center">
<img src="/course/static/chapter9/gpt-j.png" alt="An image showing the gradio interface for the gpt-j model" width="80%"/>
</p>


### Loading from Hugging Face Spaces
To load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass `spaces/` followed by the model name:
    
    ```
    gr.Interface.load("spaces/eugenesiow/remove-bg", inputs="webcam", title="Remove your webcam background!").launch()
    ```
    
One of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting `Interface` object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models).
